<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap"
      rel="stylesheet">
<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen"/>

<html lang="en">
<head>
	<title>SLAMP: Stochastic Latent Appearance and Motion Prediction</title>
    <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/
        if you update and want to force Facebook to re-scrape. -->
	<meta property="og:image" content="Path to my teaser.jpg"/>
	<meta property="og:title" content="SLAMP: Stochastic Latent Appearance and Motion Prediction" />
	<meta property="og:description" content="Stochastic Video Prediction" />
    <!-- Twitter automatically scrapes this. Go to https://cards-dev.twitter.com/validator?
        if you update and want to force Twitter to re-scrape. -->
    <meta property="twitter:card"          content="Stochastic Video Prediction" />
    <meta property="twitter:title"         content="SLAMP: Stochastic Latent Appearance and Motion Prediction" />
    <meta property="twitter:description"   content="Stochastic Video Prediction" />
    <meta property="twitter:image"         content="Path to my teaser.jpg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Add your Google Analytics tag here -->
    <script async
            src="https://www.googletagmanager.com/gtag/js?id=UA-97476543-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());
        gtag('config', 'UA-97476543-1');
    </script>

</head>

<body>
<div class="container">
    <div class="title">
        SLAMP: Stochastic Latent Appearance and Motion Prediction
    </div>

    <div class="venue">
        In ICCV 2021
    </div>

    <br><br>

    <div class="author">
        <a href="https://kaanakan.github.io" target="_blank">Adil Kaan Akan</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://web.cs.hacettepe.edu.tr/~erkut/" target="_blank">Erkut Erdem</a><sup>2</sup>
    </div>
    <div class="author">
        <a href="https://aykuterdem.github.io/" target="_blank">Aykut Erdem</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://mysite.ku.edu.tr/fguney/" target="_blank">Fatma Guney</a><sup>1</sup>
    </div>

    <br><br>

    <div class="affiliation"><sup>1&nbsp;</sup><a href="https://ai.ku.edu.tr" target="_blank"> Koc University Is Bank AI Center</a></div>
    <div class="affiliation"><sup>2&nbsp;</sup><a href="https://vision.cs.hacettepe.edu.tr/" target="_blank">Hacettepe University Computer Vision Lab</a></div>

    <br><br>

    <div class="links"><a>[Paper coming]</a></div>
    <div class="links"><a>[Code coming]</a></div>

    <br><br>

    <img style="width: 80%;" src="./resources/teaser_mnist.gif" alt="MNIST."/> <br><br>
    <img style="width: 80%;" src="./resources/teaser_kth.gif" alt="KTH."/> <br><br>
    <img style="width: 80%;" src="./resources/teaser_bair.gif" alt="BAIR."/>
    <br>
    <br>
    <p style="width: 80%;">
        Example predictions for MNIST, KTH and BAIR datasets</a>.
    </p>

    <br><br>
    <hr>

    <h1>Abstract</h1>
    <p style="width: 80%;">
        Motion is an important cue for video prediction and often utilized by separating video content into static and dynamic components. Most of the previous work utilizing motion is deterministic but there are stochastic methods that can model the inherent uncertainty of the future.
        Existing stochastic models either do not reason about motion explicitly or make limiting assumptions about the static part. In this paper, we reason about appearance and motion in the video stochastically by predicting the future based on the motion history.
        Explicit reasoning about motion without history already reaches the performance of current stochastic models. The motion history further improves the results by allowing to predict consistent dynamics several frames into the future. Our model performs comparably to the state-of-the-art models on the generic video prediction datasets, however, significantly outperforms them on two challenging real-world autonomous driving datasets with complex motion and dynamic background.
    </p>

    <br><br>
    <hr>

    <!-- <h1>Video</h1>
    <div class="video-container">
        <iframe src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameBorder="0"
                allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
    </div>

    <br><br>
    <hr> -->

    <h1>Method Overview</h1>
    <img style="width: 80%;" src="./resources/method.jpg"
         alt="Method overview figure"/>
    <br>
    <a class="links">[Code is coming.]</a>

    <br><br>
    <hr>

    <h1>Results</h1>
    <img style="width: 80%;" src="./resources/result_mnist.gif"
         alt="Results figure"/> 
         <br><br>
    <img style="width: 80%;" src="./resources/result_kth.gif"
         alt="Results figure"/> 
         <br><br>
    <img style="width: 80%;" src="./resources/result_bair.gif"
         alt="Results figure"/>

    <br><br>
    <hr>

    <h1>Paper</h1>
    <div class="paper-thumbnail">
        <a href="https://arxiv.org">
            <img class="layered-paper-big" width="100%" src="./resources/paper.jpg" alt="Paper thumbnail"/>
        </a>
    </div>
    <div class="paper-info">
        <h3>SLAMP: Stochastic Latent Appearance and Motion Prediction</h3>
        <p>Adil Kaan Akan, Erkut Erdem, Aykut Erdem and Fatma Guney</p>
        <p>In ICCV, 2021.</p>
        <!-- <pre><code>@InProceedings{author20XXtitle,
    title = {Creative and Descriptive Paper Title},
    author = {Author, First and Author, Second and Author, Third and Author, Fourth and Author, Fifth},
    booktitle = {Conference},
    year = {20XX},
}</code></pre> -->
    </div>

    <br><br>
    <hr>

    <h1>Acknowledgements</h1>
    <p style="width: 80%;">
        We would like to thank <a href="https://mlia.lip6.fr/franceschi/" target="_blank">Jean-Yves Franceschi</a> and <a href="https://github.com/edouardelasalles" target="_blank">Edouard Delasalles</a> for providing technical and numerical details of the baseline performances,
        and <a href="http://www.denizyuret.com/" target="_blank">Deniz Yuret</a> for helpful discussions and comments. This work is supported by <a href="https://ai.ku.edu.tr" target="_blank">KUIS AI Center</a>.
    </p>

    <br><br>
</div>

</body>

</html>
